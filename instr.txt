To execute the py-spark client:

//redirecting it to interpreter
❯ clear;/opt/spark/bin/pyspark < pyspark_client.py 
                    OR
//submitting it with the right version of kafka
❯ clear;spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2 pyspark_client.py

To execute tweepy server:

❯ clear;python3 twitter_server.py   

To start zookeeper,kafka and kafka manager follow the below instructions:

    Terminal 1: 
        Move inside the kafka directory
        ❯ source /etc/environment
        ❯ zookeeper-server-start.sh config/zookeeper.properties   

    Terminal 2:
        Move into the kafka directory
        ❯ source /etc/environment
        ❯ kafka-server-start.sh config/server.properties 
    
    -----------------------OPTIONAL----------------------------
    Terminal 3:
        Move into ~/CMAK-master/target/universal/cmak-3.0.0.6
        Run:
            ❯ bin/cmak -Dconfig.file=conf/application.conf -Dhttp.port=8080  
        On browser,visit 0.0.0.0/8080

Creating topics in kafka:
❯ kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test

Listing topics in kafka:
❯ kafka-topics.sh --list --bootstrap-server localhost:9092     

List messages in a topic:
❯ kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning

Producing messages into a kafak topic:
❯ clear;kafka-console-producer.sh --bootstrap-server localhost:9092 --topic <topic_name>

Running Kafka consumer:
❯ python3 kafka_consumer.py  

Todo:
Learn about:
->batch size vs windows
->how window aggregates work

Here is the problem statement for the project.
1. Collect twitter feed for 30 minutes with any 5 hash tags. [done]
2. Ingest into spark. [done]
3. Use 6 tumbling windows of 5 minutes each. [not done]
4. Aggregate count of each of these hash tags for each of the 5 minute windows. [done]
5. Publish them as topics into Kafka. [done]
6. Export topic wise count by window into any db.
Note: make any assumptions as necessary . Use any language. You cannot use cloud infrastructure.

|.......|
         |.......|